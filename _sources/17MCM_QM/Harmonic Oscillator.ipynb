{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmonic Oscillator\n",
    "\n",
    "To compute the solutions to the harmonic oscillator, we use our previous methods of constructng the Hamiltonian as a matrix, and then using the linear algebra of Numpy to find the eigen values and eigen vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "hbar=1\n",
    "m=1\n",
    "omega=1\n",
    "N = 2014\n",
    "a = 20.0\n",
    "x = np.linspace(-a/2.,a/2.,N)\n",
    "h = x[1]-x[0] # Should be equal to 2*np.pi/(N-1)\n",
    "V = .5*m*omega*x*x\n",
    "# V[N/2]=2/h   # This would add a \"delta\" spike in the center.\n",
    "Mdd = 1./(h*h)*(np.diag(np.ones(N-1),-1) -2* np.diag(np.ones(N),0) + np.diag(np.ones(N-1),1))\n",
    "H = -(hbar*hbar)/(2.0*m)*Mdd + np.diag(V) \n",
    "En,psiT = np.linalg.eigh(H) # This computes the eigen values and eigenvectors\n",
    "psi = np.transpose(psiT) \n",
    "# The psi now contain the wave functions ordered so that psi[n] if the n-th eigen state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to verify that these resuls make sense, so we plot the wave functions and compute the norms. Note that the eigenvectors are normalized in such a way that $\\sum psi_n^2(x_i) = 1$. This *does not* take into account the step size that we used for discretizing the space. We want to plot the wave functions in such a way that they plot the same independent of our choice of step size. To do this we need to divide the array of numbers by $\\sqrt{\\Delta x}$ before plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the normalization of the wave function arrays.\n",
    "notok=False\n",
    "for n in range(len(psi)):\n",
    "    # s = np.sum(psi[n]*psi[n])\n",
    "    s = np.linalg.norm(psi[n])  # This does the same as the line above.\n",
    "    if np.abs(s - 1) > 0.00001: # Check if it is different from one.\n",
    "        print(\"Wave function {} is not normalized to 1 but {}\".format(n,s))\n",
    "        notok=True\n",
    "\n",
    "if not notok:\n",
    "    print(\"All the psi_n(x) are normalized.\")\n",
    "\n",
    "fig2 = plt.figure(figsize=[10,7])\n",
    "plt.title('Harmonic Oscillator')\n",
    "plt.ylabel('$\\psi(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.plot([0,0],[-6,V[0]],color=\"blue\")\n",
    "plt.plot([-a/2.,a/2.],[0,0],color=\"blue\")\n",
    "plt.plot(x,0.1*V,color=\"grey\",label=\"V(x) scaled by 0.1\")\n",
    "plt.ylim((-.8,1.))\n",
    "plt.xlim((-6.,6.))\n",
    "for i in range(0,5):\n",
    "    if psi[i][N//8] < 0:\n",
    "        plt.plot(x,-psi[i]/np.sqrt(h),label=\"$E_{}$={:3.1f}\".format(i,En[i]))\n",
    "    else:\n",
    "        plt.plot(x,psi[i]/np.sqrt(h),label=\"$E_{}$={:3.1f}\".format(i,En[i]))\n",
    "\n",
    "plt.title(\"Solution to harmonic oscillator\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Harmonic_Oscillator_WaveFunctions.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to now plot the initial wave function. We could try to shift the already calculated $\\psi_0(x)$ array, but it is better to compute the function from a formula. The *main reason* for making this plot is to make sure the *normalization* of the function is correct. We would want the *same normalization* as our $\\psi_n(x)$ arrays, so we need to muliply the function by $\\sqrt{\\Delta x}$, which we then divide out again when we plot. Doing this makes sure that the $c_n$ factors we compute later are correct and with the same normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=[10,7])\n",
    "plt.title('Harmonic Oscillator and displaced ground state.')\n",
    "plt.ylabel('$\\psi(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.plot([0,0],[-6,V[0]],color=\"blue\")\n",
    "plt.plot([-a/2.,a/2.],[0,0],color=\"blue\")\n",
    "plt.plot(x,0.1*V,color=\"grey\",label=\"V(x) scaled by 0.1\")\n",
    "plt.ylim((-.1,1.))\n",
    "plt.xlim((-5.,8.))\n",
    "a0=5.\n",
    "alpha = (m*omega/(np.pi*hbar))**0.25\n",
    "psi0 = np.sqrt(h)*alpha*np.exp(-(x-a0)**2*m*omega/(2*hbar))  # This is the formula for the displaced state.\n",
    "n0 = np.linalg.norm(psi0)\n",
    "print(\"Check the normalization of psi0: \",n0)\n",
    "plt.plot(x,psi0/np.sqrt(h),label=\"Displaced state $\\Psi(x,0)$\")\n",
    "plt.plot(x,-psi[0]/np.sqrt(h),label=\"Ground state $\\psi_0(x)$\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Displaced_state.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the $c_n$ factors as a simple sum of the product of the initial wave and the $\\psi_n(x)$ eigen states. There are many ways to accomplish this, looping over the $N$ eigen states. The way I do this below is particularly efficient, creating a new Numpy array of the $c_n$ factors. The line commented out does the calculation using list comprehension. The second line does this as a matrix multiplication. \n",
    "\n",
    "We now compute the energy of this initial state, so we can plot the line on our graph. This was not part of the homework assignment, but it is nice to be able to draw this. We compute the energy as: . We also compute the energy as $E=\\int \\Psi^*(x,t=0)  \\hat{\\mathrm{H}} \\Psi(x,t-0)$, and compare. \n",
    "\n",
    "Once we have the $c_n$ we can sum them to make sure the normalization is indeed correct: $\\sum |c_n|^2 =1$.\n",
    "\n",
    "We can also use them to calculate the expactation value of the energy of the state: $<E>=\\sum |c_n|^2 E_n$, which we can check against an algebraic computation:\n",
    "$$ <E> = <T> + <V> = \\frac{1}{2}\\hbar\\omega + \\frac{1}{2}m\\omega^2 |x_0|^2 = \\frac{1}{2} + \\frac{1}{2} 5^2 = 13$$\n",
    "And finally we can also compute it directly from the Hamiltonian:\n",
    "$$<E> = <\\Psi(x,0)| \\hat{\\mathrm{H}} | \\Psi(x,0)> = \\int \\Psi^*(x,0)H \\Psi(x,0) dx$$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cn=np.array([np.sum(psi[i]*psi0) for i in range(N)],dtype='float')\n",
    "cn = psi.dot(psi0)\n",
    "print(cn[0:18])\n",
    "print(\"Check sum: {:6.4f}\".format(np.sum(cn*cn)))\n",
    "E = np.sum(np.conjugate(cn)*cn*En)\n",
    "print(\"<E> = {:9.4f}\".format(E))\n",
    "E_check = np.sum( np.conjugate(psi0)*H.dot(psi0)) \n",
    "print(\"Check E=\",E_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to compute:\n",
    "$$\\Psi(x,t)=\\sum_n c_n \\psi_n(x) e^{-i(n+\\frac{1}{2})\\omega t}$$\n",
    "For a particular time $t$ we thus want an array of numbers representing $\\Psi$ at that time. A technical detail here is that we want to sum all the $n$ values for a particular $x_i$ of the product $c_n*\\psi_n*\\phi(t)$. Our wavefunctions are arranged in such a way that this would be a sum over the columns instead of over the rows (which is what we did when checking the normalization). We can circumvent this priblem by using the original transposed version, psiT, of the wavefunctions. Below are three different implementation of this function, the first one is a bit more straight forward but slow, the second one is a bit faster (about a factor of 2.5), the third is fastest.\n",
    "\n",
    "At this point you should start to worry about numerical accuracy. It turns out that for this particular situation the method we are using is accurate enough, and the solution is *stable*, that is, there are no diverging terms in the calculation. This will not be true for all situations where you solve the Schr√∂dinger equation using matrix inversion (i.e. finding the eigen vectors). In many situations, including scattering, you will need to use more sophisticated ways of obtaining solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version creates an array of zeros, to which it then sequentially adds each of the terms in the sum.\n",
    "# Note that we use the global psi array.\n",
    "def psi_xt(t,cn):\n",
    "    out = np.zeros(N,dtype='complex128')\n",
    "    for n in range(N): \n",
    "        out += cn[n]*psi[n]*np.exp(-1j*(n+0.5)*omega*t)\n",
    "    return(out)\n",
    "\n",
    "# This version uses np.sum to accomplish the same thing as the function above.\n",
    "def psi_xt2(t,cn):\n",
    "    n = np.arange(len(cn)) \n",
    "    times = np.exp(-1j*(n+0.5)*omega*t)\n",
    "    out = psiT.dot(cn*times)\n",
    "    return(out)\n",
    "\n",
    "# This version uses np.sum and now also the previously calculated energyes.\n",
    "# This way, psi_xt3 will work even if the potential is distorted and the energy levels are no longer (n+0.5)*hbar*omega\n",
    "def psi_xt3(t,cn):\n",
    "    out = psiT.dot(cn*np.exp(-1j*En*t/hbar))\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=[10,5])\n",
    "plt.title('Harmonic Oscillator')\n",
    "plt.ylabel('$\\psi(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.plot([0,0],[-6,V[0]],color=\"blue\")\n",
    "plt.plot([-a/2.,a/2.+1.],[0,0],color=\"blue\")\n",
    "plt.plot(x,0.05*V,color=\"grey\",label=\"V(x) scaled by 0.05\")\n",
    "plt.plot([-a/2.,a/2.],[E*0.05,E*0.05],color=\"grey\",linestyle=\"dashed\",label=\"<E> scaled by 0.05\")\n",
    "plt.ylim((-.1,0.8))\n",
    "# plt.plot(x,psi0/np.sqrt(h),color='#dddddd')\n",
    "for t in [0.,np.pi/4.,np.pi/2.,3.*np.pi/4.,np.pi]: # np.linspace(0,np.pi,8):\n",
    "    print(t)\n",
    "    plt.plot(x,np.abs(psi_xt3(t,cn))**2/h,label=\"t={:5.3}$\\pi$\".format(t/np.pi))\n",
    "plt.legend()\n",
    "plt.savefig(\"Displaced_state_vs_time.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can turn the restults into a little movie for a more dramatic effect. The 'animation' from matplotlib can do this for us. Since we run inside an HTML notebook, we need to render the movie into an html5 video for it to display.\n",
    "\n",
    "The animation system wants an init() function that draws the frame, the axis, and everything else that does not change. The animate(t) function will then only draw the updated curve. To do this efficiently, we ask for the actual line object that is drawn for the plot, and then we only update the data for that line object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "fig3 = plt.figure(figsize=[10,7])\n",
    "ax = fig3.add_subplot(111, autoscale_on=False, xlim=(-10, 10), ylim=(-0.1, 1.))\n",
    "ax.grid()\n",
    "\n",
    "line, = ax.plot([], [], lw=2,color='red')\n",
    "time_template = 'time = {:9.2f}s'\n",
    "time_text = ax.text(0.05, 0.93, '', transform=ax.transAxes)\n",
    "\n",
    "def init():\n",
    "    plt.title('Harmonic Oscillator')\n",
    "    plt.ylabel('$\\psi(x)$')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.plot([0,0],[-6,V[0]],color=\"blue\")\n",
    "    plt.plot([-a/2.,a/2.],[0,0],color=\"blue\")\n",
    "    plt.plot(x,0.05*V,color=\"grey\",label=\"V(x) scaled by 0.05\")\n",
    "    plt.plot([-a/2.,a/2.],[E*0.05,E*0.05],color=\"grey\",linestyle=\"dashed\",label=\"<E> scaled by 0.05\")\n",
    "    line.set_data([], [])\n",
    "    time_text.set_text(time_template.format(0.))\n",
    "    return line, time_text\n",
    "\n",
    "def animate(t):\n",
    "    #t = (float(i)/100.)*(4.*np.pi/omega)\n",
    "    line.set_data(x,np.abs(psi_xt3(t,cn)/np.sqrt(h)))\n",
    "    time_text.set_text(time_template.format(t))\n",
    "    return line,  time_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate and run the animation. This will take a bit of time to calculate, about 30 seconds. To see the animation, you *must* run a live version of the notebook, not the static version on GitHub. If you do this in a notebook, then you need to turn the animation into a video and then display the the video in the notebook. If you run this from the prompt, you can show the animation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 30     # Frame rate in Hz. Make higher for smoother movie, but it takes longer to compute.\n",
    "time_slowdown = 10  # Run time x times slower than normal. Since omega=1, we want this about 10.\n",
    "ani = animation.FuncAnimation(fig3, animate, np.linspace(0,2*np.pi/omega,frame_rate*time_slowdown),\n",
    "                              interval=1000./frame_rate, blit=True, init_func=init)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerically Solving the Schr√∂dinger Equation\n",
    "\n",
    "In this Python notebook, we will work on finding a purely numerical solution to the time independent Schr√∂dinger Equation (SE). \n",
    "$$ -\\frac{\\hbar^2}{2m}\\frac{d^2}{d x^2} \\psi(x) + V(x)\\psi(x) = E\\psi(x)$$\n",
    "\n",
    "In the process, I hope to convince you, even more than before, that that the SE is indeed an eigen equation.\n",
    "\n",
    "This notebook can easily be modified for any other potential you would like to try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "The method we will use here is called the [\"Finite Difference Method\"](https://en.wikipedia.org/wiki/Finite_difference_method) (see the linked Wikipedia article). In this method we will turn the function $\\psi(x)$ into a vector, which is a list in Python, and the operator of the differential equation into a *matrix*. We then end up with a matrix eigenequation, which we can diagonalize to get our answer.\n",
    "\n",
    "### Discretization\n",
    "The process of discretization is simply turning our continuous space $x$, into a discrete number of steps, $N$, and our function $\\psi(x)$ into an array of size $N$. We thus have $N$ values $x_i$, which have a stepsize $h = \\Delta x = x_{i+1} - x_i$. Our choice of the *size* of our space, $N$, turns out to be important. Too large a number will slow down our computation and require too much computer memory, too small a number and the answers we compute will not be sufficiently accurate. A common practice is to start with a small number $N$ and then increase it until the accuracy is acceptable. The actual value you obtain in the end will depend on the problem you are studying. \n",
    "\n",
    "### Forward and Backward first order differential\n",
    "We first need to develop how we will take the derivative of our function. Going back to our introduction to calculus, we remember that the derivative was defined as:\n",
    "$$\n",
    "\\frac{d}{dx} f(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x) - f(x)}{\\Delta x} \\approx \\frac{f(x+h) - f(x)}{h} + \\mathrm{O}(h)\n",
    "$$\n",
    "When we take a *finite difference*, we simply not take the limit all the way down to 0, but stop at $\\Delta x = h$. Note that for this equation we evaluate the point just *after* $x$, which we call the *forward difference*. If you actually let $\\Delta x \\rightarrow 0$, then this does not matter, but if you do a finite difference, you can also do:\n",
    "$$\n",
    "\\frac{d}{dx} f(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x) - f(x-\\Delta x)}{\\Delta x} \\approx \\frac{f(x) - f(x-h)}{h} + \\mathrm{O}(h)\n",
    "$$\n",
    "which is known as the *backward difference*. \n",
    "\n",
    "You can also comput a *central difference*, but cannot use steps of $\\frac{1}{2}\\Delta x$, since that does not exist in our space. The central difference is then a combination of the previous two:\n",
    "$$\n",
    "\\frac{d}{dx} f(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x) - f(x-\\Delta x)}{2\\Delta x}\\approx \\frac{f(x+h) - f(x-h)}{2h} + \\mathrm{O}(h^2)\n",
    "$$\n",
    "This last one is a little more accurate than the first two.\n",
    "\n",
    "Note that for any of these approximations to a derivative, we have a problem at the edges of our space. (In Python, C and Java, our space goes from $n=0$ to $n=N-1$, in Fortran $n=1$ to $N$.) Either on one end or the other, there is no $x-\\Delta x$ or $x+\\Delta x$. Here, we are just not going to worry about this detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix representation\n",
    "\n",
    "We now want to turn the equation into a matrix equation for us to evaluate. If you just want to take the derivative of a function stored in an array, then this is not needed, you can run a loop and evaluate the equation for each $x_i$, but if you want to solve a differential equation, we need the matrix.\n",
    "\n",
    "We introduce the vectors $f(x) = [f_0,f_1,f_2,...,f_{N-1}]$ and for the derivative $f'(x) = [f'_0,f'_1,f'_2...,f'_{N-1}]$. The forward difference derivative can then be written as:\n",
    "$$ f'_i = (f_{i+1} - f_i)/h $$\n",
    "And the matrix equation for the forward difference derivative is just:\n",
    "$$\n",
    "\\begin{pmatrix}f'_0 \\\\ f'_1 \\\\\\vdots \\\\ f'_{N-1}\\end{pmatrix} = \\frac{1}{h}\n",
    "\\begin{pmatrix} -1 & 1 & 0 & & \\\\ 0 & -1 & 1 & & \\\\ & & \\ddots & \\ddots \\\\\n",
    "& & & -1 & \\end{pmatrix}\\begin{pmatrix}f_0 \\\\ f_1 \\\\\\vdots \\\\ f_{N-1}\\end{pmatrix}\n",
    "$$\n",
    "We note that the last entry in the matrix will not be correct because there is no element for $N$. We can fix this up by taking the *backward* derivative at the last point.\n",
    "\n",
    "We now check that this works. Using Python and Numpy we will take the derivative of $\\sin(x)$ and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Define the number of points in our space, N\n",
    "N = 128\n",
    "a = 2*np.pi\n",
    "# Define the x space from 0 to a with N-1 divisions.\n",
    "x = np.linspace(0,2*np.pi,N)\n",
    "# We want to store step size, this is the reliable way:\n",
    "h = x[1]-x[0] # Should be equal to 2*np.pi/(N-1)\n",
    "# Compute the function, y = sin(x). With numpy this is easy:\n",
    "y = np.sin(x)\n",
    "# We compute the matrix using the np.diag(np.ones(N),0) which creates a \n",
    "# diagonal matrix of 1 of NxN size. Multiply by -1 to get -1 diagonal array.\n",
    "# You get an +1 off-diagonal array of ones, with np.diag(np.ones(N-1),1)\n",
    "# Note that you need N-1 for an NxN array, since the off diagonal is one smaller.\n",
    "# Add the two together and normalize by 1/h\n",
    "Md = 1./h*(np.diag( -1.*np.ones(N),0) + np.diag(np.ones(N-1),1))\n",
    "# Compute the derivative of y into yp by matrix multiplication:\n",
    "yp = Md.dot(y)\n",
    "# Plot the results.\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x,y)\n",
    "plt.plot(x[:-1],yp[:-1]) # Don't plot last value, which is invalid\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second order Differential\n",
    "We can now extend this method to the second order differential. If we take the backward differential of the result of a forward differential, we get:\n",
    "$$\n",
    "\\frac{d^2}{dx^2}f(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f'(x)-f'(x-\\Delta x)}{\\Delta x} =  \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x) - f(x) - (f(x) - f(x-\\Delta x))}{\\Delta x^2} \\\\\n",
    "\\frac{d^2}{dx^2}f(x) = \\lim_{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x) - 2f(x) + f(x-\\Delta x))}{\\Delta x^2} \\approx \\frac{f(x+h) - 2f(x) + f(x-h))}{h^2}\n",
    "$$\n",
    "So in the discrete space we can write this as:\n",
    "$$ f''_i = (f_{i+1} - 2f_i + f_{i-1})/h^2 $$\n",
    "And finally, as a matrix equation, the second derivative is then:\n",
    "$$\n",
    "\\begin{pmatrix}f''_0 \\\\ f''_1 \\\\ f''_2 \\\\\\vdots \\\\ f''_{N-1}\\end{pmatrix} = \\frac{1}{h^2}\n",
    "\\begin{pmatrix} -2 & 1 & 0 & 0 & \\\\ 1 & -2 & 1 & 0 & \\\\ \n",
    "0& 1 & -2 & 1 &  \\\\ &  & \\ddots & \\ddots & \\ddots &\\\\\n",
    "&  & & 1 & -2 \\end{pmatrix}\\begin{pmatrix}f_0 \\\\ f_1 \\\\ f_2 \\\\\\vdots \\\\ f_{N-1}\\end{pmatrix}\n",
    "$$\n",
    "Where now we note that at both ends of our array we will get an inaccurate answer unless we do some fixup. The fixup in this case is to use the same elements as the row below (at the start) or the row above (at the end), so we get $f''_0 = f''_1$ and $f''_{N-1} = f''_{N-2}$, which is not great but better than the alternative.\n",
    "\n",
    "We can now try this matrix in Python and compute the second derivative of our $y(x)$ array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mdd = 1./(h*h)*(np.diag(np.ones(N-1),-1) + np.diag( -2.*np.ones(N),0) + np.diag(np.ones(N-1),1))\n",
    "print(Mdd)\n",
    "ypp = Mdd.dot(y)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x,y)\n",
    "plt.plot(x[:-1],yp[:-1])     # Last value is invalid, don't plot\n",
    "plt.plot(x[1:-1],ypp[1:-1])  # First and last value is invalid.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Schr√∂dinger Equation\n",
    "\n",
    "We can now setup the Schrodinger Equation as a matrix equation:\n",
    "$$\n",
    "\\hat H = \\frac{\\hbar^2}{2m}\\frac{d^2}{d x^2} + V \\\\\n",
    "\\hat H \\psi(x) = E \\psi(x)\n",
    "$$\n",
    "We now know the matrix for taking the second order derivative. The matrix for the potential is simply the values of the potential on the diagonal of the matrix: $\\mathbf{V}_{i=j} = V_i$. \n",
    "\n",
    "Writing out the matrix for $\\mathbf{H}$ we get:\n",
    "$$\n",
    "\\mathbf{H} = \\frac{-\\hbar^2}{2 m h^2} \\begin{pmatrix} -2 & 1 & 0 & 0 & \\\\ 1 & -2 & 1 & 0 & \\\\ \n",
    "0& 1 & -2 & 1 &  \\\\ &  & \\ddots & \\ddots & \\ddots &\\\\\n",
    "&  & & 1 & -2 \\end{pmatrix} + \n",
    "\\begin{pmatrix} V_0 & 0 & 0 & & \\\\ 0 & V_1 & 0 & & \\\\ 0 & 0 & V_2 & & \\\\ & & &\\ddots & \\\\ &&&&V_{N-1}\\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "It is worth looking at the matrix of the Hamiltonian and notice the symmetry: $\\mathbf{H}^T = \\mathbf{H}$, so the transpose of the matrix is identical to the matrix. Since the matrix is *real* everywhere, the complex conjugate is also the same: $\\mathbf{H}^*=\\mathbf{H}$. Combining these two statements, we can say that the Hamiltonian is Hermetian: $\\mathbf{H}^\\dagger = \\mathbf{H}$. We will come back to this later in the course.\n",
    "\n",
    "### Infinite Square Well\n",
    "The very simplest system to solve for is the infinite square well, for which $V=0$. We will readily recognize the results as alternating $\\cos(x)$ and $\\sin(x)$ functions, and the energy levels are:\n",
    "$$\n",
    "E_i = \\frac{n^2\\pi^2\\hbar^2}{2ma^2}\n",
    "$$\n",
    "First, we need to discuss a subtlety. The Infinite Square Well from $-a/2$ to $a/2$ has $V=\\infty$ *at* these points. We get into trouble trying to entery $\\infty$ in our potential, so what we need to do is just limit the coputational space from $-a/2+h$ to $a/2-h$, where $h$ is our step size. That way we force the wavefunction to zero at the end points. \n",
    "We compute this in the next box. I create $x_{full}$ as the full x-axis from $-a/2$ to $a/2$, but take $N+2$ steps. I then leave out the first and last point when calculating the wavefunctions. At the end, before plotting, I add a zero to the beginning and end of the wavefunctions, so that we get the expected result for plotting.\n",
    "\n",
    "Note I again import everything and setup all the definitions, so this block is stand-alone, and can be copy-pasted into another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as scl\n",
    "hbar=1\n",
    "m=1\n",
    "N = 512\n",
    "a = 1.0\n",
    "x = np.linspace(-a/2.,a/2.,N)\n",
    "# We want to store step size, this is the reliable way:\n",
    "h = x[1]-x[0] # Should be equal to 2*np.pi/(N-1)\n",
    "V = 0.*x\n",
    "Mdd = 1./(h*h)*(np.diag(np.ones(N-1),-1) -2* np.diag(np.ones(N),0) + np.diag(np.ones(N-1),1))\n",
    "H = -(hbar*hbar)/(2.0*m)*Mdd + np.diag(V) \n",
    "E,psiT = np.linalg.eigh(H) # This computes the eigen values and eigenvectors\n",
    "psi = np.transpose(psiT)   # We take the transpose of psiT to the wavefunction vectors can accessed as psi[n]\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to plot these wavefunctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "for i in range(5):\n",
    "    if psi[i][N-10] < 0:   # Flip the wavefunctions if it is negative at large x, so plots are more consistent.\n",
    "        plt.plot(x,-psi[i]/np.sqrt(h),label=\"$E_{}$={:>8.3f}\".format(i,E[i]))\n",
    "    else:\n",
    "        plt.plot(x,psi[i]/np.sqrt(h),label=\"$E_{}$={:>8.3f}\".format(i,E[i]))\n",
    "    plt.title(\"Solutions to the Infinite Square Well\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Infinite_Square_Well_WaveFunctions.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now also want to check that the energy levels do indeed correspond to the known levels:\n",
    "$$\n",
    "E_n = \\frac{n^2 \\pi^2 \\hbar^2}{2 m a^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    n = i+1\n",
    "    print(\"E[{}] = {:9.4f}, E_{} ={:9.4f}\".format(n,E[i],n, n*n*np.pi**2*hbar*hbar/(2*m*a*a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that as N gets larger the results for the energy levels become more accurate. Values of N as large as 1024 or 20148 still give results quickly on modern computers.\n",
    "\n",
    "A final test shows the accuracy of our calculation in the orthonormality of the states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    for i in range(5):\n",
    "        print(\"{:16.9e}\".format(np.sum(psi[j]*psi[i])),end=\" \")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
